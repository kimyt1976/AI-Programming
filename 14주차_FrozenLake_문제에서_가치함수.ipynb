{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMO3a9qbLB7UWO3FnN4ohSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimyt1976/AI-Programming/blob/main/14%EC%A3%BC%EC%B0%A8_FrozenLake_%EB%AC%B8%EC%A0%9C%EC%97%90%EC%84%9C_%EA%B0%80%EC%B9%98%ED%95%A8%EC%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C09f4fahGKMD",
        "outputId": "0dacfded-c0b4-4bfa-aec8-533199571cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.94 0.93 0.95 0.94]\n",
            " [0.94 0.   0.96 0.95]\n",
            " [0.95 0.97 0.95 0.96]\n",
            " [0.96 0.   0.   0.86]\n",
            " [0.   0.   0.   0.94]\n",
            " [0.   0.   0.   0.  ]\n",
            " [0.   0.98 0.   0.96]\n",
            " [0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.93]\n",
            " [0.92 0.   0.   0.  ]\n",
            " [0.91 0.99 0.   0.97]\n",
            " [0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.  ]\n",
            " [0.   0.   0.99 0.  ]\n",
            " [0.98 0.99 1.   0.98]\n",
            " [0.   0.   0.   0.  ]]\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
        "Q=np.zeros([env.observation_space.n,env.action_space.n])     #Q배열 초기화\n",
        "\n",
        "rho=0.90              #학습율\n",
        "lamda=0.99            #할인율\n",
        "eps=1.0               #앱실론\n",
        "eps_decay=0.999       #삭감비율\n",
        "\n",
        "n_episode=3000\n",
        "length_episode=100\n",
        "\n",
        "#최적 행동 가치함수 찾기(탐사와 탐험의 균형 추구)\n",
        "for i in range(n_episode):\n",
        "  s=env.reset()          #새로운 에피소드 시작\n",
        "  for j in range(length_episode):\n",
        "    r=np.random.random()\n",
        "    eps=max(0.01,eps*eps_decay)        #앱실론 조금씩 줄여나감\n",
        "    if(r<eps):                         #erp 비율만큼 임의 선택\n",
        "      a=np.random.randint(0,env.action_space.n)\n",
        "    else:\n",
        "      argmaxs=np.argwhere(Q[s,:]==np.amax(Q[s,:])).flatten().tolist()\n",
        "      a=np.random.choice(argmaxs)\n",
        "    s1,r,done,_=env.step(a)\n",
        "    Q[s,a]=Q[s,a]+rho*(r+lamda*np.max(Q[s1,:])-Q[s,a])\n",
        "    s=s1\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "print(Q)"
      ]
    }
  ]
}